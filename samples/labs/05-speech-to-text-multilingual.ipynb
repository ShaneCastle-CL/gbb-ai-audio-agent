{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "343b4d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed directory to: c:\\Users\\pablosal\\Desktop\\gbb-ai-audio-agent\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "# set the directory to the location of the script\n",
    "try:\n",
    "    os.chdir(\"../..\")\n",
    "    target_directory = os.getenv(\n",
    "        \"TARGET_DIRECTORY\", os.getcwd()\n",
    "    )  # Use environment variable if available\n",
    "    if os.path.exists(target_directory):\n",
    "        os.chdir(target_directory)\n",
    "        print(f\"Changed directory to: {os.getcwd()}\")\n",
    "        logging.info(f\"Successfully changed directory to: {os.getcwd()}\")\n",
    "    else:\n",
    "        logging.error(f\"Directory does not exist: {target_directory}\")\n",
    "except Exception as e:\n",
    "    logging.exception(f\"An error occurred while changing directory: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "930a1a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-07 00:01:54,894] INFO - micro: Azure Monitor tracing initialized for speech recognizer\n",
      "INFO:micro:Azure Monitor tracing initialized for speech recognizer\n",
      "[2025-08-07 00:01:54,908] INFO - micro: Creating SpeechConfig with API key authentication\n",
      "INFO:micro:Creating SpeechConfig with API key authentication\n",
      "[2025-08-07 00:01:54,924] INFO - micro: Azure Monitor tracing initialized for speech synthesizer\n",
      "INFO:micro:Azure Monitor tracing initialized for speech synthesizer\n",
      "[2025-08-07 00:01:54,938] INFO - micro: Creating SpeechConfig with API key authentication\n",
      "INFO:micro:Creating SpeechConfig with API key authentication\n",
      "[2025-08-07 00:01:54,951] INFO - micro: Speech synthesizer initialized successfully\n",
      "INFO:micro:Speech synthesizer initialized successfully\n"
     ]
    }
   ],
   "source": [
    "from src.speech.text_to_speech import SpeechSynthesizer\n",
    "from src.speech.speech_recognizer import StreamingSpeechRecognizerFromBytes\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "if \"az_speech_recognizer_stream_client\" not in locals():\n",
    "    az_speech_recognizer_stream_client = StreamingSpeechRecognizerFromBytes(\n",
    "        vad_silence_timeout_ms=800,\n",
    "        use_semantic_segmentation=False,\n",
    "        audio_format=\"pcm\",\n",
    "        candidate_languages=[\"en-US\", \"fr-FR\", \"de-DE\", \"es-ES\", \"it-IT\"],\n",
    "        enable_diarisation=True,\n",
    "        speaker_count_hint=2,\n",
    "        enable_neural_fe=False,\n",
    "    )\n",
    "\n",
    "if \"az_speach_synthesizer_client\" not in locals():\n",
    "    az_speach_synthesizer_client = SpeechSynthesizer()\n",
    "\n",
    "# Ensure Azure OpenAI client is initialized only if not already defined\n",
    "if \"client\" not in locals():\n",
    "    client = AzureOpenAI(\n",
    "        api_version=\"2025-02-01-preview\",\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d74aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define end-of-sentence markers for TTS\n",
    "TTS_ENDS = {\".\", \"!\", \"?\", \";\", \"\\n\"}\n",
    "\n",
    "# Flags and buffers\n",
    "is_synthesizing = False\n",
    "user_buffer = \"\"\n",
    "assistant_buffer = \"\"\n",
    "tts_thread = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c00c034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-07 00:01:55,267] INFO - micro: Starting recognition from byte stream…\n",
      "INFO:micro:Starting recognition from byte stream…\n",
      "[2025-08-07 00:01:55,283] INFO - micro: Speech-SDK prepare_start – format=pcm  neuralFE=False  diar=True\n",
      "INFO:micro:Speech-SDK prepare_start – format=pcm  neuralFE=False  diar=True\n",
      "[2025-08-07 00:01:55,300] INFO - micro: Speech-SDK ready (neuralFE=False, diarisation=True, speakers=2)\n",
      "INFO:micro:Speech-SDK ready (neuralFE=False, diarisation=True, speakers=2)\n",
      "[2025-08-07 00:01:55,319] INFO - micro: Recognition started.\n",
      "INFO:micro:Recognition started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎙️ Speak now...\n",
      "🗣️ User (partial) in en-US: hello\n",
      "🗣️ User (partial) in en-US: hello how are\n",
      "🗣️ User (partial) in en-US: hello how are you\n",
      "🧾 User (final) in en-US: Hello, how are you?\n",
      "Hello!Hi there, I am a assistant_speak callback!\n",
      "Syntetixing: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-07 00:02:11,066] INFO - micro: [🔊] Starting streaming speech synthesis for text: Hello!...\n",
      "INFO:micro:[🔊] Starting streaming speech synthesis for text: Hello!...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'm just a computer program, so I don't have feelings, but I'm here and ready to help you.Hi there, I am a assistant_speak callback!\n",
      "Syntetixing: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-07 00:02:11,131] INFO - micro: [🔊] Starting streaming speech synthesis for text: I'm just a computer program, so I don't have feeli...\n",
      "INFO:micro:[🔊] Starting streaming speech synthesis for text: I'm just a computer program, so I don't have feeli...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " How can I assist you today?Hi there, I am a assistant_speak callback!\n",
      "Syntetixing: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-07 00:02:11,165] INFO - micro: [🔊] Starting streaming speech synthesis for text: How can I assist you today?...\n",
      "INFO:micro:[🔊] Starting streaming speech synthesis for text: How can I assist you today?...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🗣️ User (partial) in en-US: hello\n",
      "🗣️ User (partial) in en-US: hello i'm just\n",
      "🗣️ User (partial) in en-US: hello i'm just a\n",
      "🗣️ User (partial) in en-US: hello i'm just a computer program\n",
      "🗣️ User (partial) in en-US: hello i'm just a computer program so i don't\n",
      "🗣️ User (partial) in en-US: hello i'm just a computer program so i don't have\n",
      "🗣️ User (partial) in en-US: hello i'm just a computer program so i don't have feelings\n",
      "🗣️ User (partial) in en-US: hello i'm just a computer program so i don't have feelings but\n",
      "🗣️ User (partial) in en-US: hello i'm just a computer program so i don't have feelings but i'm\n",
      "🗣️ User (partial) in en-US: hello i'm just a computer program so i don't have feelings but i'm here and ready\n",
      "🗣️ User (partial) in en-US: hello i'm just a computer program so i don't have feelings but i'm here and ready to\n",
      "🗣️ User (partial) in en-US: hello i'm just a computer program so i don't have feelings but i'm here and ready to help\n",
      "🗣️ User (partial) in en-US: hello i'm just a computer program so i don't have feelings but i'm here and ready to help you\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 93\u001b[39m\n\u001b[32m     90\u001b[39m                     collected_messages.clear()\n\u001b[32m     91\u001b[39m     \u001b[38;5;28mprint\u001b[39m()  \u001b[38;5;66;03m# finish line after streaming LLM response\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m time.sleep(\u001b[32m0.1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗣️ User (partial) in en-US: hello i'm just a computer program so i don't have feelings but i'm here and ready to help you how can i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗣️ User (partial) in en-US: hello i'm just a computer program so i don't have feelings but i'm here and ready to help you how can i assist\n",
      "🗣️ User (partial) in en-US: hello i'm just a computer program so i don't have feelings but i'm here and ready to help you how can i assist you\n",
      "🗣️ User (partial) in en-US: hello i'm just a computer program so i don't have feelings but i'm here and ready to help you how can i assist you today\n",
      "🧾 User (final) in en-US: Hello, I'm just a computer program so I don't have feelings but I'm here and ready to help you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "import os, time, threading\n",
    "\n",
    "\n",
    "def on_final(text, lang):\n",
    "    global user_buffer\n",
    "    user_buffer += text.strip() + \"\\n\"\n",
    "    print(f\"🧾 User (final) in {lang}: {text}\")\n",
    "\n",
    "\n",
    "def assistant_speak(text):\n",
    "    global is_synthesizing\n",
    "    print(\"Hi there, I am a assistant_speak callback!\")\n",
    "    is_synthesizing = True\n",
    "    print(\"Syntetixing:\", is_synthesizing)\n",
    "    az_speach_synthesizer_client.start_speaking_text(text)\n",
    "\n",
    "\n",
    "def on_partial(text, lang):\n",
    "    global is_synthesizing\n",
    "    if is_synthesizing:\n",
    "        # az_speach_synthesizer_client.stop_speaking()\n",
    "        is_synthesizing = False\n",
    "    print(f\"🗣️ User (partial) in {lang}: {text}\")\n",
    "\n",
    "\n",
    "az_speech_recognizer_stream_client.set_partial_result_callback(on_partial)\n",
    "az_speech_recognizer_stream_client.set_final_result_callback(on_final)\n",
    "\n",
    "# Start recognition\n",
    "az_speech_recognizer_stream_client.start()\n",
    "print(\"🎙️ Speak now...\")\n",
    "\n",
    "# Start mic streaming thread\n",
    "import pyaudio\n",
    "\n",
    "RATE, CHANNELS, CHUNK = 16000, 1, 1024\n",
    "audio = pyaudio.PyAudio()\n",
    "stream = audio.open(\n",
    "    format=pyaudio.paInt16,\n",
    "    channels=CHANNELS,\n",
    "    rate=RATE,\n",
    "    input=True,\n",
    "    frames_per_buffer=CHUNK,\n",
    ")\n",
    "\n",
    "\n",
    "def mic_loop():\n",
    "    while True:\n",
    "        data = stream.read(CHUNK, exception_on_overflow=False)\n",
    "        az_speech_recognizer_stream_client.write_bytes(data)\n",
    "\n",
    "\n",
    "threading.Thread(target=mic_loop, daemon=True).start()\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "\n",
    "user_buffer = \"\"  # This should be filled in by your STT callback as before\n",
    "\n",
    "while True:\n",
    "    if user_buffer:\n",
    "        full_conversation = (\n",
    "            \"\\n\".join([f\"{m['role'].capitalize()}: {m['content']}\" for m in messages])\n",
    "            + f\"\\nUser: {user_buffer}\"\n",
    "        )\n",
    "        messages.append({\"role\": \"user\", \"content\": user_buffer})\n",
    "        user_buffer = \"\"  # clear after using\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            stream=True,\n",
    "            messages=messages,\n",
    "            max_tokens=4096,\n",
    "            temperature=1.0,\n",
    "            top_p=1.0,\n",
    "            model=os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_ID\"),\n",
    "        )\n",
    "\n",
    "        collected_messages = []\n",
    "        last_tts_request = None\n",
    "\n",
    "        for chunk in completion:\n",
    "            if chunk.choices and hasattr(chunk.choices[0].delta, \"content\"):\n",
    "                chunk_text = chunk.choices[0].delta.content\n",
    "                if chunk_text:\n",
    "                    collected_messages.append(chunk_text)\n",
    "                    print(chunk_text, end=\"\", flush=True)\n",
    "                    # Check for sentence end to stream to TTS\n",
    "                    if chunk_text in TTS_ENDS:\n",
    "                        text = \"\".join(collected_messages).strip()\n",
    "                        last_tts_request = assistant_speak(text)\n",
    "                        collected_messages.clear()\n",
    "        print()  # finish line after streaming LLM response\n",
    "\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfa1d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-07 00:02:24,040] INFO - micro: [🛑] Stopping speech synthesis...\n",
      "INFO:micro:[🛑] Stopping speech synthesis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-07 00:02:24,178] WARNING - micro: Recognition canceled: SpeechRecognitionCanceledEventArgs(session_id=d01476a8f2404869b08f70ab43d05912, result=SpeechRecognitionResult(result_id=04c69c2191234b0fb145603c54632ccc, text=\"\", reason=ResultReason.Canceled))\n",
      "WARNING:micro:Recognition canceled: SpeechRecognitionCanceledEventArgs(session_id=d01476a8f2404869b08f70ab43d05912, result=SpeechRecognitionResult(result_id=04c69c2191234b0fb145603c54632ccc, text=\"\", reason=ResultReason.Canceled))\n",
      "[2025-08-07 00:02:24,186] WARNING - micro: Reason: CancellationReason.EndOfStream, Error: \n",
      "WARNING:micro:Reason: CancellationReason.EndOfStream, Error: \n",
      "[2025-08-07 00:02:24,193] INFO - micro: Session stopped.\n",
      "INFO:micro:Session stopped.\n"
     ]
    }
   ],
   "source": [
    "az_speech_recognizer_stream_client.close_stream()\n",
    "az_speach_synthesizer_client.stop_speaking()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audioagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
