{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "343b4d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed directory to: c:\\Users\\pablosal\\Desktop\\gbb-ai-audio-agent\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "# set the directory to the location of the script\n",
    "try:\n",
    "    os.chdir(\"../..\")\n",
    "    target_directory = os.getenv(\n",
    "        \"TARGET_DIRECTORY\", os.getcwd()\n",
    "    )  # Use environment variable if available\n",
    "    if os.path.exists(target_directory):\n",
    "        os.chdir(target_directory)\n",
    "        print(f\"Changed directory to: {os.getcwd()}\")\n",
    "        logging.info(f\"Successfully changed directory to: {os.getcwd()}\")\n",
    "    else:\n",
    "        logging.error(f\"Directory does not exist: {target_directory}\")\n",
    "except Exception as e:\n",
    "    logging.exception(f\"An error occurred while changing directory: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "930a1a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-06 11:24:14,203] INFO - micro: Azure Monitor tracing initialized for speech recognizer\n",
      "INFO:micro:Azure Monitor tracing initialized for speech recognizer\n",
      "[2025-08-06 11:24:14,208] INFO - micro: Creating SpeechConfig with API key authentication\n",
      "INFO:micro:Creating SpeechConfig with API key authentication\n",
      "[2025-08-06 11:24:14,213] INFO - micro: Azure Monitor tracing initialized for speech synthesizer\n",
      "INFO:micro:Azure Monitor tracing initialized for speech synthesizer\n",
      "[2025-08-06 11:24:14,220] INFO - micro: Creating SpeechConfig with API key authentication\n",
      "INFO:micro:Creating SpeechConfig with API key authentication\n",
      "[2025-08-06 11:24:14,225] INFO - micro: Speech synthesizer initialized successfully\n",
      "INFO:micro:Speech synthesizer initialized successfully\n"
     ]
    }
   ],
   "source": [
    "from src.speech.text_to_speech import SpeechSynthesizer\n",
    "from src.speech.speech_recognizer import StreamingSpeechRecognizerFromBytes\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "if \"az_speech_recognizer_stream_client\" not in locals():\n",
    "    az_speech_recognizer_stream_client = StreamingSpeechRecognizerFromBytes(\n",
    "        vad_silence_timeout_ms=800,\n",
    "        use_semantic_segmentation=False,\n",
    "        audio_format=\"pcm\",\n",
    "        candidate_languages=[\"en-US\", \"fr-FR\", \"de-DE\", \"es-ES\", \"it-IT\"],\n",
    "        enable_diarisation=True,\n",
    "        speaker_count_hint=2,\n",
    "        enable_neural_fe=False,\n",
    "    )\n",
    "\n",
    "if \"az_speach_synthesizer_client\" not in locals():\n",
    "    az_speach_synthesizer_client = SpeechSynthesizer(voice=\"en-US-Ava:DragonHDLatestNeural\")\n",
    "\n",
    "# Ensure Azure OpenAI client is initialized only if not already defined\n",
    "if \"client\" not in locals():\n",
    "    client = AzureOpenAI(\n",
    "        api_version=\"2025-02-01-preview\",\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d74aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define end-of-sentence markers for TTS\n",
    "TTS_ENDS = {\".\", \"!\", \"?\", \";\", \"\\n\"}\n",
    "\n",
    "# Flags and buffers\n",
    "is_synthesizing = False\n",
    "user_buffer = \"\"\n",
    "assistant_buffer = \"\"\n",
    "tts_thread = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c00c034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-06 11:24:14,688] INFO - micro: Speech-SDK prepare_start ‚Äì format=pcm  neuralFE=False  diar=True\n",
      "INFO:micro:Speech-SDK prepare_start ‚Äì format=pcm  neuralFE=False  diar=True\n",
      "[2025-08-06 11:24:14,699] INFO - micro: Speech-SDK ready (neuralFE=False, diarisation=True, speakers=2)\n",
      "INFO:micro:Speech-SDK ready (neuralFE=False, diarisation=True, speakers=2)\n",
      "[2025-08-06 11:24:14,711] INFO - micro: Starting recognition from byte stream‚Ä¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:micro:Starting recognition from byte stream‚Ä¶\n",
      "[2025-08-06 11:24:14,720] INFO - micro: Speech-SDK prepare_start ‚Äì format=pcm  neuralFE=False  diar=True\n",
      "INFO:micro:Speech-SDK prepare_start ‚Äì format=pcm  neuralFE=False  diar=True\n",
      "[2025-08-06 11:24:14,733] INFO - micro: Speech-SDK ready (neuralFE=False, diarisation=True, speakers=2)\n",
      "INFO:micro:Speech-SDK ready (neuralFE=False, diarisation=True, speakers=2)\n",
      "[2025-08-06 11:24:14,753] INFO - micro: Recognition started.\n",
      "INFO:micro:Recognition started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéôÔ∏è Speak now‚Ä¶\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 90\u001b[39m\n\u001b[32m     88\u001b[39m                 buf=[]\n\u001b[32m     89\u001b[39m     \u001b[38;5;28mprint\u001b[39m()\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m time.sleep(\u001b[32m0.1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-3 (mic_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\audioagent\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\audioagent\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\audioagent\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\pablosal\\AppData\\Local\\Temp\\ipykernel_39032\\3547244998.py\", line 59, in mic_loop\n",
      "  File \"c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\audioagent\\Lib\\site-packages\\pyaudio\\__init__.py\", line 570, in read\n",
      "    return pa.read_stream(self._stream, num_frames,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "OSError: [Errno -9999] Unanticipated host error\n"
     ]
    }
   ],
   "source": [
    "import os, time, json, threading, logging\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import pyaudio                                                         # pip install pyaudio\n",
    "\n",
    "def _extract_speaker(evt: speechsdk.SpeechRecognitionEventArgs) -> str | None:\n",
    "    \"\"\"Pull SpeakerId from the hidden JsonResult blob (if diarisation is enabled).\"\"\"\n",
    "    blob = evt.result.properties.get(\n",
    "        speechsdk.PropertyId.SpeechServiceResponse_JsonResult, \"\")\n",
    "    if blob:\n",
    "        try:\n",
    "            return str(json.loads(blob).get(\"SpeakerId\"))\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 3.  STT callbacks (with speaker tags)\n",
    "##############################################################################\n",
    "def _partial_evt(evt):\n",
    "    global is_synthesizing\n",
    "    if is_synthesizing:\n",
    "        is_synthesizing = False\n",
    "    spk = _extract_speaker(evt)\n",
    "    tag = f\"[S{spk}]\" if spk is not None else \"\"\n",
    "    print(f\"üó£Ô∏è {tag} partial: {evt.result.text}\")\n",
    "\n",
    "def _final_evt(evt):\n",
    "    global user_buffer\n",
    "    spk = _extract_speaker(evt)\n",
    "    tag = f\"[S{spk}]\" if spk is not None else \"\"\n",
    "    print(f\"üßæ {tag} final  : {evt.result.text}\")\n",
    "    user_buffer += evt.result.text.strip() + \"\\n\"\n",
    "\n",
    "# Hook directly into the underlying SpeechRecognizer events\n",
    "# (this guarantees we receive the full event object)\n",
    "rec = az_speech_recognizer_stream_client.speech_recognizer\n",
    "if rec is None:                 # first run: build recogniser\n",
    "    az_speech_recognizer_stream_client.prepare_start()\n",
    "    rec = az_speech_recognizer_stream_client.speech_recognizer\n",
    "\n",
    "rec.recognizing.connect(_partial_evt)\n",
    "rec.recognized .connect(_final_evt)\n",
    "\n",
    "##############################################################################\n",
    "# 4.  Start recognition & mic streaming\n",
    "##############################################################################\n",
    "az_speech_recognizer_stream_client.start()\n",
    "print(\"üéôÔ∏è Speak now‚Ä¶\")\n",
    "\n",
    "RATE, CHANNELS, CHUNK = 16000, 1, 1024\n",
    "pa = pyaudio.PyAudio()\n",
    "mic= pa.open(format=pyaudio.paInt16, channels=CHANNELS, rate=RATE,\n",
    "             input=True, frames_per_buffer=CHUNK)\n",
    "\n",
    "def mic_loop():\n",
    "    while True:\n",
    "        az_speech_recognizer_stream_client.write_bytes(\n",
    "            mic.read(CHUNK, exception_on_overflow=False))\n",
    "threading.Thread(target=mic_loop, daemon=True).start()\n",
    "\n",
    "##############################################################################\n",
    "# 5.  OpenAI chat ‚ûú Azure TTS\n",
    "##############################################################################\n",
    "def assistant_speak(text:str):\n",
    "    global is_synthesizing\n",
    "    is_synthesizing = True\n",
    "    az_speach_synthesizer_client.start_speaking_text(text)\n",
    "\n",
    "messages=[{\"role\":\"system\",\"content\":\"You are a helpful assistant.\"}]\n",
    "while True:\n",
    "    if user_buffer:\n",
    "        messages.append({\"role\":\"user\",\"content\":user_buffer})\n",
    "        user_buffer = \"\"\n",
    "        stream = client.chat.completions.create(\n",
    "            stream=True, messages=messages,\n",
    "            model=os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_ID\"),\n",
    "            max_tokens=4096, temperature=1.0, top_p=1.0)\n",
    "\n",
    "        buf=[]\n",
    "        for chunk in stream:\n",
    "            part = getattr(chunk.choices[0].delta, \"content\", \"\")\n",
    "            if part:\n",
    "                buf.append(part)\n",
    "                print(part, end=\"\", flush=True)\n",
    "                if part in TTS_ENDS:\n",
    "                    assistant_speak(\"\".join(buf).strip())\n",
    "                    buf=[]\n",
    "        print()\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfa1d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-06 10:45:58,878] INFO - micro: [üõë] Stopping speech synthesis...\n",
      "INFO:micro:[üõë] Stopping speech synthesis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-06 10:45:59,049] WARNING - micro: Recognition canceled: SpeechRecognitionCanceledEventArgs(session_id=9993690b4d444f6e96612b9f9d8e3a57, result=SpeechRecognitionResult(result_id=dcace2598fb847c484b5fe936d86722d, text=\"\", reason=ResultReason.Canceled))\n",
      "WARNING:micro:Recognition canceled: SpeechRecognitionCanceledEventArgs(session_id=9993690b4d444f6e96612b9f9d8e3a57, result=SpeechRecognitionResult(result_id=dcace2598fb847c484b5fe936d86722d, text=\"\", reason=ResultReason.Canceled))\n",
      "[2025-08-06 10:45:59,067] WARNING - micro: Reason: CancellationReason.EndOfStream, Error: \n",
      "WARNING:micro:Reason: CancellationReason.EndOfStream, Error: \n",
      "[2025-08-06 10:45:59,080] INFO - micro: Session stopped.\n",
      "INFO:micro:Session stopped.\n"
     ]
    }
   ],
   "source": [
    "az_speech_recognizer_stream_client.close_stream()\n",
    "az_speach_synthesizer_client.stop_speaking()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audioagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
